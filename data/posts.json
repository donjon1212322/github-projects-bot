[
    {
        "project_id": 935422300,
        "content": "ðŸ”¥ <b>search-navigator</b> | HTML\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nEnhancing Google search experience with keyboard navigation and quick category switching.\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ Keyboard navigation of Google search results\n<br>\nðŸ“– <b>Summary:</b>\nSearch Navigator is a Chrome extension that improves Google search usability by enabling keyboard navigation of search results and providing shortcuts for switching between different search categories. It also offers quick access to Google Maps and YouTube, and allows for customization of keyboard shortcuts. The extension aims to provide a more efficient and intuitive search experience.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/nwatab/search-navigator?embed=0\">View Project</a>\nâ€¢ <a href=\"https://chromewebstore.google.com/detail/search-result-navigator/fpinaaaiplppifhmkjdfkimodkkdnoha?embed=0\">Homepage</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
        "media_url": "https://opengraph.githubassets.com/bac6b715202d168f26a0099c6aa08724e7bd25f53865dd98f80367c9f94793b8/nwatab/search-navigator",
        "platform": "telegram",
        "quality_score": 0.7499999999999999
    },
    {
        "project_id": 1012122505,
        "content": "ðŸš€ <b>br-cli</b> | JavaScript\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nBrowser automation for AI agents, enabling them to interact with web pages through a command-line interface.\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ Browser Action\nâ€¢ LLM friendly output\nâ€¢ Daemon mode\nâ€¢ Structured web page view\nâ€¢ Secrete management\n<br>\nðŸ“– <b>Summary:</b>\nbr-cli is a command-line tool designed to facilitate browser automation for AI agents. It allows AI agents like Claude Code and Gemini CLI to control web browsers, manage sessions, and perform tasks such as login and data extraction. The tool features LLM-friendly output, daemon mode for persistent sessions, structured web page views, secret management, and history tracking for replay and scripting.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/browsemake/br-cli?embed=0\">View Project</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
        "media_url": "https://opengraph.githubassets.com/5a73161e4c3efbebac729e17d43c4b5943346612800c03393b5900a0beaf36e9/browsemake/br-cli",
        "platform": "telegram",
        "quality_score": 0.7499999999999999
    },
    {
        "project_id": 966243985,
        "content": "âœ¨ <b>trackers</b> | Python\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nProviding a unified and modular library for multi-object tracking, allowing users to easily integrate and compare different tracking algorithms with various object detectors.\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ Unified library for multi-object tracking\nâ€¢ Clean room re-implementations of tracking algorithms\nâ€¢ Modular design for easy tracker swapping\n<br>\nðŸ“– <b>Summary:</b>\nThe `trackers` repository offers a unified Python library for multi-object tracking. It provides clean-room re-implementations of leading tracking algorithms with a modular design, enabling easy integration with object detectors from popular libraries. This allows users to easily swap and compare different trackers for their specific use cases.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/roboflow/trackers?embed=0\">View Project</a>\nâ€¢ <a href=\"https://trackers.roboflow.com/?embed=0\">Homepage</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
        "media_url": "https://opengraph.githubassets.com/0457514051fc71d30c6c0e8264e0b687e0fdc785fb4f065bdb004a8431d4aebc/roboflow/trackers",
        "platform": "telegram",
        "quality_score": 1.0000000000000002
    },
    {
        "project_id": 607845880,
        "content": "ðŸ’¡ <b>maxtext</b> | Python\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nTraining and inference of large language models.\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ High performance LLM framework\nâ€¢ Scalable training and inference on TPUs and GPUs\nâ€¢ Written in pure Python/Jax\nâ€¢ Supports Llama 2, Llama 3, Llama 4, Mistral and Mixtral family, Gemma, Gemma 2, Gemma 3, and DeepSeek family models\n<br>\nðŸ“– <b>Summary:</b>\nMaxText is a high-performance, scalable, open-source LLM framework written in pure Python/Jax. It targets Google Cloud TPUs and GPUs for both training and inference. MaxText supports various open models, including Llama, Mistral, Gemma, and DeepSeek families, aiming to provide a launching point for ambitious LLM projects in research and production.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/AI-Hypercomputer/maxtext?embed=0\">View Project</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
        "media_url": "https://opengraph.githubassets.com/567849449221d2ee7cb96116411fa2d5902017d8a13c627b73b7f6a13cec346a/AI-Hypercomputer/maxtext",
        "platform": "telegram",
        "quality_score": 0.85
    },
    {
        "project_id": 962528913,
        "content": "ðŸ’¡ <b>reTermAI</b> | Python\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nSuggesting relevant terminal commands based on user's shell history using AI.\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ Recommends terminal commands based on history using OpenAI or Gemini\nâ€¢ Supports intelligent matching by keyword or partial input\nâ€¢ Easy installation via pip\nâ€¢ Supports zsh and bash shell history\nâ€¢ API keys managed via .env\n<br>\nðŸ“– <b>Summary:</b>\nreTermAI is a smart command assistant that suggests relevant terminal commands based on your past shell history, leveraging AI models like OpenAI and Gemini. It supports intelligent matching by keyword or partial input and is easily installable via pip, supporting both zsh and bash shells. API keys are managed securely via a .env file.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/pie0902/reTermAI?embed=0\">View Project</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
        "media_url": "https://opengraph.githubassets.com/aba2b17e0253c76b2b04bb7bd56180595bfdb32622f9ed0e0c9e96908d4c5ad0/pie0902/reTermAI",
        "platform": "telegram",
        "quality_score": 0.4
    },
    {
        "project_id": 654122609,
        "content": "âœ¨ <b>lmdeploy</b> | Python\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nCompressing, deploying, and serving large language models (LLMs).\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ LLM Compression\nâ€¢ LLM Deployment\nâ€¢ LLM Serving\nâ€¢ PyTorch Inference Engine\nâ€¢ TurboMind Inference Engine\n<br>\nðŸ“– <b>Summary:</b>\nLMDeploy is a toolkit designed to streamline the process of working with large language models. It focuses on compressing models for efficient storage, deploying them across various platforms, and serving them for inference. The toolkit includes features like quantization, a PyTorch inference engine, and support for VLMs.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/InternLM/lmdeploy?embed=0\">View Project</a>\nâ€¢ <a href=\"https://lmdeploy.readthedocs.io/en/latest/?embed=0\">Homepage</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
        "media_url": "https://opengraph.githubassets.com/a1a0de223eaba705e92456a73b4a7cd656a53ad9c6417d31eda7ec4d825398bb/InternLM/lmdeploy",
        "platform": "telegram",
        "quality_score": 0.95
    }
]