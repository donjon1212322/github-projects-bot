{
    "project_id": 1028391416,
    "content": "âœ¨ <b>duelr</b> | TypeScript\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nEvaluating and comparing LLM responses across different providers based on latency, cost, and quality metrics.\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ Parallel Comparison\nâ€¢ Comprehensive Metrics\nâ€¢ Quality Scoring\nâ€¢ Cost Transparency\nâ€¢ Extensible\n<br>\nðŸ“– <b>Summary:</b>\nDuelr is an open-source tool for comparing the performance and quality of different Large Language Models (LLMs). It allows users to test multiple LLMs simultaneously, tracking metrics like latency, token usage, cost, and quality scores for length simplicity, readability, and JSON validity, facilitating informed decisions about LLM selection.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/stashlabs/duelr?embed=0\">View Project</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
    "media_url": "https://opengraph.githubassets.com/e6f153c4e348ef424e42490a9e282bea9aad1c788bd09b9f42a84affc4445f2c/stashlabs/duelr",
    "platform": "telegram",
    "quality_score": 0.4
}