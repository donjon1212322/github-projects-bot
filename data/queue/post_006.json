{
    "project_id": 1037741738,
    "content": "âœ¨ <b>RLinf</b> | Python\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nPost-training foundation models (LLMs, VLMs, VLAs) via reinforcement learning.\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ Macro-to-Micro Flow (M2Flow)\nâ€¢ Flexible Execution Modes (Collocated, Disaggregated, Hybrid)\nâ€¢ Auto-scheduling Strategy\nâ€¢ Embodied Agent Support\nâ€¢ Online Reinforcement Learning Support\n<br>\nðŸ“– <b>Summary:</b>\nRLinf is an open-source infrastructure for post-training foundation models using reinforcement learning. It provides a flexible and scalable framework with features like macro-to-micro flow, flexible execution modes (collocated, disaggregated, hybrid), and auto-scheduling, supporting embodied agent development and integration with various VLA models and simulators.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/RLinf/RLinf?embed=0\">View Project</a>\nâ€¢ <a href=\"https://rlinf.readthedocs.io/en/latest/?embed=0\">Homepage</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
    "media_url": "https://opengraph.githubassets.com/3f11ee200f8e71d8c003e654271d4e2c8d200e4b71b2efe6f23a8990f8dc1cf4/RLinf/RLinf",
    "platform": "telegram",
    "quality_score": 1.1000000000000003
}