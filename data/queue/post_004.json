{
    "project_id": 1039587768,
    "content": "âœ¨ <b>osaurus</b> | Swift\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nLocal LLM inference on Apple Silicon Macs with OpenAI and Ollama-compatible APIs.\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ Native MLX runtime\nâ€¢ Apple Silicon only\nâ€¢ OpenAI API compatible\nâ€¢ Ollama-compatible\nâ€¢ Function/Tool calling\n<br>\nðŸ“– <b>Summary:</b>\nOsaurus is a native, Apple Silicon-only local LLM server, similar to Ollama. It leverages Apple's MLX framework for optimized performance on M-series chips. It features a SwiftUI app and a SwiftNIO server, providing OpenAI and Ollama-compatible endpoints for local LLM inference.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/dinoki-ai/osaurus?embed=0\">View Project</a>\nâ€¢ <a href=\"https://osaurus.ai?embed=0\">Homepage</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
    "media_url": "https://opengraph.githubassets.com/ad2ec6c3f477a8d9fead16edb205d328d9f6d4ec584c2acd593494377d8f3995/dinoki-ai/osaurus",
    "platform": "telegram",
    "quality_score": 0.9
}