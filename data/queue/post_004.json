{
    "project_id": 913468419,
    "content": "ðŸš€ <b>LLaVA-Mini</b> | Python\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nEfficient image and video understanding with reduced computational cost and memory usage.\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ Efficient image, high-resolution image, and video understanding using a single vision token.\nâ€¢ 77% FLOPs reduction compared to previous methods.\nâ€¢ Low-latency responses (40 milliseconds).\n<br>\nðŸ“– <b>Summary:</b>\nLLaVA-Mini is a large multimodal model designed for efficient image, high-resolution image, and video understanding. It achieves this efficiency by representing images with only one vision token, significantly reducing computational effort, response latency, and memory usage. The model maintains performance comparable to previous LLaVA versions while offering substantial improvements in efficiency and resource utilization.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/ictnlp/LLaVA-Mini?embed=0\">View Project</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
    "media_url": "https://opengraph.githubassets.com/83b0d6bac88fa3b734518857da362b04d258dbad5f072cb4828fa28028a8617f/ictnlp/LLaVA-Mini",
    "platform": "telegram",
    "quality_score": 0.3
}