{
    "project_id": 967096214,
    "content": "ðŸš€ <b>ml-comotion</b> | Python\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nDetecting and tracking 3D poses of multiple people from a single camera in real-time, even in crowded and occluded environments.\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ Detects and tracks detailed 3D poses of multiple people from a single monocular camera stream.\n<br>\nðŸ“– <b>Summary:</b>\nThe CoMotion repository provides tools and scripts for detecting and tracking detailed 3D human poses from monocular video streams. It uses a combination of per-frame detection and learned pose updates to maintain temporally coherent predictions, even in crowded scenes with occlusions. The repository includes pretrained models, demo scripts, and visualization tools, supporting both video and single-image inputs.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/apple/ml-comotion?embed=0\">View Project</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
    "media_url": "https://opengraph.githubassets.com/0a4e148dd2640a8db4ddddfeed091fdd2be2000fae267e291c06a800ed746a1a/apple/ml-comotion",
    "platform": "telegram",
    "quality_score": 0.55
}