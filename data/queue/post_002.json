{
    "project_id": 1028391416,
    "content": "ðŸŒŸ <b>duelr</b> | TypeScript\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nEvaluating and comparing Large Language Model responses across different providers.\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ Parallel Comparison of LLMs\nâ€¢ Comprehensive Metrics (latency, token usage, cost)\nâ€¢ Quality Scoring (length simplicity, readability, JSON validity)\nâ€¢ Cost Transparency\nâ€¢ Extensible provider system\n<br>\nðŸ“– <b>Summary:</b>\nDuelr is an open-source tool designed to evaluate and compare the performance of various Large Language Models (LLMs). It allows users to test multiple LLMs simultaneously, tracking key metrics such as latency, token usage, and cost, while also providing quality scores for readability and JSON validity. Duelr aims to provide transparency and facilitate informed decisions when selecting LLMs.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/stashlabs/duelr?embed=0\">View Project</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
    "media_url": "https://opengraph.githubassets.com/43eb5d4bbcdd6502309e9f19598505e033d1b5c03bb5d71f707fe9bbce2b24ad/stashlabs/duelr",
    "platform": "telegram",
    "quality_score": 0.5499999999999999
}