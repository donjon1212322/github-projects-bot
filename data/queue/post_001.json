{
    "project_id": 817827211,
    "content": "ðŸŒŸ <b>vid2text</b> | Python\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nExtracting searchable transcriptions from video and audio sources.\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ Multi-source support (YouTube, local videos, M3U8 streams)\nâ€¢ Local transcription using MLX Whisper or OpenAI Whisper\nâ€¢ SQLite storage with Datasette web interface\nâ€¢ Batch processing via YAML configuration\n<br>\nðŸ“– <b>Summary:</b>\nThe vid2text tool enables users to create searchable transcripts from various video and audio sources, including YouTube videos, local files, and M3U8 streams. It leverages local Whisper models for transcription and stores the results in an SQLite database, accessible through a Datasette web interface. Batch processing is supported via YAML configuration files.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/kashw1n/vid2text?embed=0\">View Project</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
    "media_url": "https://opengraph.githubassets.com/407f9ca622e37c3d47239833c6ab796b4ce50106c636553609c5f3392ba7fc84/kashw1n/vid2text",
    "platform": "telegram",
    "quality_score": 0.6499999999999999
}