{
    "project_id": 156939672,
    "content": "ðŸ”¥ <b>onnxruntime</b> | C++\n<br>\nðŸŽ¯ <b>Primary Use Case:</b>\nAccelerating machine learning inference and training across various platforms and hardware.\n<br>\nâœ¨ <b>Key Features:</b>\nâ€¢ Cross-platform inference and training accelerator\nâ€¢ Supports models from various deep learning frameworks and classical machine learning libraries\nâ€¢ Compatible with different hardware, drivers, and operating systems\n<br>\nðŸ“– <b>Summary:</b>\nONNX Runtime is a cross-platform machine learning accelerator for both inference and training. It supports models from popular frameworks like PyTorch and TensorFlow, as well as classical machine learning libraries. By leveraging hardware acceleration and graph optimizations, ONNX Runtime aims to provide optimal performance across diverse hardware and operating systems.\n<br>\nðŸ”— <b>Links:</b>\nâ€¢ <a href=\"https://github.com/microsoft/onnxruntime?embed=0\">View Project</a>\nâ€¢ <a href=\"https://onnxruntime.ai?embed=0\">Homepage</a>\n================\n<a href='https://t.me/GitHub_Open_Source'>ðŸ”“ Open Source</a>",
    "media_url": "https://repository-images.githubusercontent.com/156939672/37b1cb00-864b-11eb-8220-76153935f7da",
    "platform": "telegram",
    "quality_score": 0.85
}