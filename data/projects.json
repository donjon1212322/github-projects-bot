[
    {
        "id": 1054352512,
        "name": "Blitzkrieg-2",
        "description": "Blitzkrieg 2 is a 2005 real-time tactics video game based on the events of World War II and is the second title in the Blitzkrieg series. The game was developed on an in-house game engine by the company Nival, primarily written in C and C++.",
        "url": "https://github.com/nival/Blitzkrieg-2",
        "language": "C++",
        "stars": 151,
        "forks": 19,
        "created_at": "2025-09-10T18:02:34Z",
        "updated_at": "2025-09-29T10:00:12Z",
        "topics": [],
        "quality_score": 0.6,
        "contributors_count": 0,
        "last_commit_date": "2025-09-20T07:28:30Z",
        "media_urls": [
            "https://opengraph.githubassets.com/616db54abf37c85cc0feea696b90f07a3e25aab3054f5fd10ffd17aebeb3b751/nival/Blitzkrieg-2"
        ],
        "homepage": "https://en.wikipedia.org/wiki/Blitzkrieg_2",
        "readme_summary": "The Blitzkrieg 2 repository contains the source code and assets for the 2005 real-time tactics game, Blitzkrieg 2. Released under a non-commercial license, it allows the community to explore, learn from, and modify the game's engine and content. The repository includes the complete game data, design documents, source code, and development tools.",
        "key_features": [
            "Complete game data and resources",
            "Design documents and art resources",
            "Game engine source code (C++)",
            "Development and build tools",
            "Map editor with documentation",
            "Localization files",
            "Lua scripting support"
        ],
        "primary_use_case": "Non-commercial research, education, and community modification of the Blitzkrieg 2 game.",
        "open_issues": 0,
        "cover_image_prompt": "A seasoned general meticulously examining a detailed battlefield map spread across a high-tech holographic table. The map displays miniature tanks and soldiers engaging in strategic maneuvers. The general uses a stylus to adjust unit formations, with the changes reflected in real-time on the holographic display. Subtle UI elements resembling game interfaces overlay the map, showing resource management and unit statistics. Digital particles flow from the stylus, enhancing the strategic planning process. The repository name, 'Blitzkrieg-2,' is subtly integrated into the table's design. The scene is set in a dimly lit war room with a focused atmosphere. The image should be in a 3D isometric illustration style with rich details and a strategic color scheme."
    },
    {
        "id": 925270205,
        "name": "cua",
        "description": "Open-source infrastructure for Computer-Use Agents. Sandboxes, SDKs, and benchmarks to train and evaluate AI agents that can control full desktops (macOS, Linux, Windows).",
        "url": "https://github.com/trycua/cua",
        "language": "Python",
        "stars": 9777,
        "forks": 502,
        "created_at": "2025-01-31T15:02:49Z",
        "updated_at": "2025-09-29T08:16:48Z",
        "topics": [
            "agent",
            "ai-agent",
            "apple",
            "computer-use",
            "containerization",
            "cua",
            "lume",
            "macos",
            "manus",
            "operator",
            "swift",
            "virtualization",
            "virtualization-framework",
            "windows",
            "windows-sandbox"
        ],
        "quality_score": 1.1000000000000003,
        "contributors_count": 0,
        "last_commit_date": "2025-09-26T05:15:49Z",
        "media_urls": [
            "https://opengraph.githubassets.com/cf753a95e6eb9c8892a65e33e2104a585a3680179204a3e38e70bb33b06e571e/trycua/cua"
        ],
        "homepage": "https://trycua.com",
        "readme_summary": "The `cua` repository provides open-source infrastructure for Computer-Use Agents, enabling AI agents to control full operating systems (macOS, Linux, Windows) within virtual containers. It includes SDKs for interacting with these virtual environments and benchmarks for evaluating agent performance, facilitating the development and deployment of AI agents capable of automating desktop tasks.",
        "key_features": [
            "Automate Windows, Linux, and macOS VMs with a consistent API.",
            "Create & manage VMs locally or using cua cloud.",
            "Run computer-use models with a consistent schema.",
            "Benchmark agents using OSWorld-Verified, SheetBench-V2, and more.",
            "Combine UI grounding models with any LLM using composed agents.",
            "Utilize new UI agent models and UI grounding models from the Model Zoo."
        ],
        "primary_use_case": "Training and evaluating AI agents that can control full desktops for automating tasks across different operating systems.",
        "open_issues": 65,
        "cover_image_prompt": "A skilled puppeteer controlling miniature virtual worlds (Windows, macOS, Linux) with glowing strings connected to AI brains. The puppeteer stands before a large monitor displaying a control panel with various metrics and data visualizations. Each virtual world shows tiny agents performing tasks within their respective OS environments. Digital particles flow from the AI brains to the virtual worlds, representing the agent's actions. The repository name, 'cua,' is subtly displayed on the monitor. The scene is set in a futuristic workshop with soft, ambient lighting. The image should be in a 3D isometric illustration style with vibrant colors and intricate details."
    },
    {
        "id": 1062117186,
        "name": "zerodistraction",
        "description": "A firefox extension that blocks distracting websites to stay focused when you need to get things done",
        "url": "https://github.com/jsattler/zerodistraction",
        "language": "JavaScript",
        "stars": 9,
        "forks": 1,
        "created_at": "2025-09-22T20:38:03Z",
        "updated_at": "2025-09-29T06:23:53Z",
        "topics": [
            "firefox",
            "firefox-addon",
            "firefox-extension",
            "firefox-webextension"
        ],
        "quality_score": 0.9,
        "contributors_count": 0,
        "last_commit_date": "2025-09-27T10:49:40Z",
        "media_urls": [
            "https://opengraph.githubassets.com/35adc4a997d65472d5c1d084849957903c302c6f9ea7020733c9a3d1a0cc64c8/jsattler/zerodistraction"
        ],
        "homepage": "https://addons.mozilla.org/en-US/firefox/addon/zerodistraction/",
        "readme_summary": "ZeroDistraction is a Firefox extension designed to help users stay focused by blocking distracting websites. It allows users to set a timer and block access to specified sites, offering presets for common distractions like social media and news, while also allowing custom exceptions and additional blocked URLs.",
        "key_features": [
            "Blocks distracting websites",
            "Configurable timer duration",
            "Categorized presets (social media, news, entertainment)",
            "URL pattern matching for flexible blocking",
            "Exception list for allowing specific URLs",
            "Manual installation option"
        ],
        "primary_use_case": "Blocking distracting websites to improve focus and productivity.",
        "open_issues": 0,
        "cover_image_prompt": "A lighthouse keeper stands resolutely at the top of a tall lighthouse, shining a focused beam of light onto a calm sea. The beam represents focused attention, cutting through a swirling fog of social media icons and news headlines that surround the lighthouse. The lighthouse itself has a small screen displaying a timer. A small UI element showing blocked website URLs is subtly integrated into the lighthouse structure. The scene is set at dusk with a warm, golden light emanating from the lighthouse. The image should be in a digital painting style with clean lines and clear details."
    },
    {
        "id": 1053508243,
        "name": "lyra",
        "description": "Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation",
        "url": "https://github.com/nv-tlabs/lyra",
        "language": "Python",
        "stars": 389,
        "forks": 20,
        "created_at": "2025-09-09T14:43:31Z",
        "updated_at": "2025-09-29T10:03:49Z",
        "topics": [],
        "quality_score": 0.44999999999999996,
        "contributors_count": 0,
        "last_commit_date": "2025-09-24T02:43:40Z",
        "media_urls": [
            "https://opengraph.githubassets.com/4bc0bd769f69e29046261f72777c26a1fe42891ed7540a257cb1585ea4808c13/nv-tlabs/lyra"
        ],
        "homepage": "https://research.nvidia.com/labs/toronto-ai/lyra/",
        "readme_summary": "The Lyra repository introduces a novel framework for generating 3D scenes from single images or videos using a self-distillation approach. It leverages video diffusion models to create synthetic training data, which is then used to train a 3D Gaussian Splatting (3DGS) decoder, enabling the generation of both static and dynamic 3D scenes without requiring multi-view training data.",
        "key_features": [
            "Generative 3D scene reconstruction",
            "Video diffusion model self-distillation",
            "Single image/video input",
            "3D Gaussian Splatting (3DGS) representation",
            "Synthetic data generation",
            "Dynamic 3D scene generation"
        ],
        "primary_use_case": "Generating virtual 3D environments for applications like gaming, robotics, autonomous driving, and industrial AI from single images or videos.",
        "open_issues": 3,
        "cover_image_prompt": "A sculptor chisels a virtual landscape out of a single photograph, bringing a 3D world to life. The sculptor's tools are digital, with UI elements floating around them. The photograph serves as the initial input, while the emerging landscape takes the form of a vibrant, detailed 3D scene. Subtle code snippets and data visualizations appear as secondary elements, connecting the artistic process to the underlying software. The scene is set in a bright, modern studio with a focus on the creative process. The image should be in 3D isometric illustration style with rich details and vibrant colors."
    },
    {
        "id": 1030580830,
        "name": "VisualPassword",
        "description": "A generator for strong and secure passwords using simple actions that are easy to remember and don‚Äôt need to be written down.",
        "url": "https://github.com/viruseg/VisualPassword",
        "language": "HTML",
        "stars": 8,
        "forks": 0,
        "created_at": "2025-08-01T22:30:59Z",
        "updated_at": "2025-09-29T09:02:20Z",
        "topics": [],
        "quality_score": 0.7,
        "contributors_count": 0,
        "last_commit_date": "2025-09-15T13:46:33Z",
        "media_urls": [
            "https://opengraph.githubassets.com/3ffb552ffb9c6766c63596ce687efc414fe883824146f957572a128d3ed80e07/viruseg/VisualPassword"
        ],
        "homepage": "https://visualpassword.pages.dev/",
        "readme_summary": "Visual Password is a tool that generates strong, recoverable passwords without needing to write them down or store them in password managers. It uses a combination of memorized emojis and a keyword to create complex passwords locally on the user's device, ensuring no data is sent or saved externally.",
        "key_features": [
            "Password generation using emojis and keywords",
            "Local password generation (no internet or database)",
            "Cross-platform availability (Web, Android, Chrome, Firefox, Telegram)",
            "Customizable character set and password length",
            "Consistent password generation from the same inputs"
        ],
        "primary_use_case": "Generating and recovering strong passwords without relying on password managers or written notes.",
        "open_issues": 0,
        "cover_image_prompt": "A skilled calligrapher in a brightly lit studio, carefully transcribing a sequence of colorful emojis from a mental image onto a digital lock. The lock glows with intricate patterns, symbolizing a strong password. The calligrapher uses a special stylus that converts the emojis into a complex code displayed on a nearby screen. Small UI elements showing password settings and character sets are subtly visible. The scene is set in a clean, modern workspace with a focus on precision and security. The image should be in a 3D isometric illustration style with vibrant colors and crisp details."
    },
    {
        "id": 1056612448,
        "name": "MIN-Safe-MAX",
        "description": "MIN - –∫–ª–∏–µ–Ω—Ç –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–∞ MAX –±–µ–∑ –æ–ø–∞—Å–Ω—ã—Ö —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π –∏ —Å–±–æ—Ä–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏",
        "url": "https://github.com/Rise0x00/MIN-Safe-MAX",
        "language": "Smali",
        "stars": 13,
        "forks": 0,
        "created_at": "2025-09-14T13:08:34Z",
        "updated_at": "2025-09-29T08:58:38Z",
        "topics": [
            "android",
            "max",
            "max-messenger",
            "messenger",
            "min",
            "smali"
        ],
        "quality_score": 0.44999999999999996,
        "contributors_count": 0,
        "last_commit_date": "2025-09-18T14:54:43Z",
        "media_urls": [
            "https://opengraph.githubassets.com/32b36004c89bbf5e1eb682def7463b802528d9454a06a2558feeddfbc34eefec/Rise0x00/MIN-Safe-MAX"
        ],
        "homepage": "",
        "readme_summary": "The MIN repository is a modified version of the MAX messenger app for Android. It focuses on privacy by removing unnecessary permissions and redirecting analytics servers to a local address, aiming to reduce tracking and enhance user control over data.",
        "key_features": [
            "Removal of over 20 permissions (camera, microphone, location, etc.)",
            "Redirection of analytics servers to 127.0.0.1"
        ],
        "primary_use_case": "Privacy-focused messaging with reduced permissions and analytics.",
        "open_issues": 0,
        "cover_image_prompt": "A skilled surgeon carefully removing surveillance cameras and microphones from a smartphone on an operating table. The phone's screen displays the MAX messenger logo. Instead of blood, digital particles flow from the removed components. A small UI element on a nearby monitor shows analytics servers being redirected to a 'safe' local address. The operating room is sterile and brightly lit, with a focus on precision. The repository name 'MIN' is subtly displayed on a medical chart. The image should be in a technical illustration style with labeled parts and a clean, focused composition."
    },
    {
        "id": 1031256025,
        "name": "Qwen-Image",
        "description": "Qwen-Image is a powerful image generation foundation model capable of complex text rendering and precise image editing.",
        "url": "https://github.com/QwenLM/Qwen-Image",
        "language": "Python",
        "stars": 5417,
        "forks": 290,
        "created_at": "2025-08-03T11:03:25Z",
        "updated_at": "2025-09-29T10:05:56Z",
        "topics": [],
        "quality_score": 0.8,
        "contributors_count": 0,
        "last_commit_date": "2025-09-22T17:32:46Z",
        "media_urls": [
            "https://opengraph.githubassets.com/a28404e76d7e0a439a58804828f4955962a630950b5fcb156642d63ecc9f91e9/QwenLM/Qwen-Image"
        ],
        "homepage": null,
        "readme_summary": "Qwen-Image is a 20B image foundation model excelling in complex text rendering and precise image editing. The model demonstrates strong general capabilities in both image generation and editing, with a particular focus on Chinese text rendering.",
        "key_features": [
            "Complex text rendering",
            "Precise image editing",
            "Multi-image editing support",
            "Enhanced single-image consistency (person, product, text)",
            "Native Support for ControlNet"
        ],
        "primary_use_case": "Image generation and editing, particularly with a focus on text rendering and manipulation.",
        "open_issues": 123,
        "cover_image_prompt": "A skilled calligrapher meticulously painting Chinese characters onto a digital canvas, seamlessly blending traditional art with modern technology. The characters morph into stunning, photorealistic images as they are completed. UI elements showing image editing tools subtly float around the canvas. The scene is set in a bright, airy studio filled with glowing particles representing digital data. The repository name, 'Qwen-Image,' is subtly displayed on a tablet. The composition is clean and focused with a harmonious blend of traditional and digital elements. The image should be in a flat design style with clear iconography and vibrant colors."
    },
    {
        "id": 673277958,
        "name": "data-juicer",
        "description": "Data processing for and with foundation models!  üçé üçã üåΩ ‚û°Ô∏è ‚û°Ô∏èüç∏ üçπ üç∑",
        "url": "https://github.com/modelscope/data-juicer",
        "language": "Python",
        "stars": 5264,
        "forks": 275,
        "created_at": "2023-08-01T09:16:41Z",
        "updated_at": "2025-09-29T09:14:03Z",
        "topics": [
            "data",
            "data-analysis",
            "data-pipeline",
            "data-processing",
            "data-science",
            "data-visualization",
            "foundation-models",
            "instruction-tuning",
            "large-language-models",
            "llm",
            "llms",
            "multi-modal",
            "pre-training",
            "synthetic-data"
        ],
        "quality_score": 0.95,
        "contributors_count": 0,
        "last_commit_date": "2025-09-22T08:53:13Z",
        "media_urls": [
            "https://opengraph.githubassets.com/b6618e1fcc97814bfa80cad98bb1f8722baad9786e1cca1ac9c2908b83adff72/modelscope/data-juicer"
        ],
        "homepage": "https://modelscope.github.io/data-juicer/",
        "readme_summary": "Data-Juicer is a comprehensive system designed for processing text and multimodal data, specifically tailored for use with foundation models and large language models (LLMs). It offers functionalities for data cleaning, synthesis, and analysis, aiming to optimize data quality for pre-training, instruction tuning, and other LLM-related tasks.",
        "key_features": [
            "Data processing for foundation models",
            "Support for text and multimodal data (image, audio, video)",
            "Data cleaning",
            "Data synthesis",
            "Data analysis",
            "Integration with ModelScope and HuggingFace",
            "Operator Zoo (collection of data processing operators)"
        ],
        "primary_use_case": "Processing and refining data to improve the performance and efficiency of foundation models and LLMs.",
        "open_issues": 27,
        "cover_image_prompt": "A skilled alchemist in a brightly lit laboratory, carefully feeding raw fruits and vegetables (representing diverse data sources) into a complex machine. The machine hums and whirs, processing the raw ingredients. From the machine's output spout flow vibrant, colorful cocktails (representing refined, high-quality data). Small UI screens display data processing pipelines and quality metrics. The repository name, 'Data-Juicer,' is subtly etched onto the machine. The scene is set in a clean, modern lab with a focus on clarity and efficiency. The image should be in a 3D isometric illustration style with rich details and vibrant colors."
    },
    {
        "id": 958603506,
        "name": "mcp-telegram",
        "description": "MCP Server for Telegram",
        "url": "https://github.com/dryeab/mcp-telegram",
        "language": "Python",
        "stars": 149,
        "forks": 18,
        "created_at": "2025-04-01T13:18:18Z",
        "updated_at": "2025-09-29T09:45:01Z",
        "topics": [
            "ai",
            "anthropic",
            "anthropic-claude",
            "bot",
            "claude",
            "cursor",
            "llm",
            "mcp",
            "model-context-protocol",
            "model-context-protocol-server",
            "mtproto",
            "telegram",
            "telegram-bot",
            "telethon"
        ],
        "quality_score": 0.35,
        "contributors_count": 0,
        "last_commit_date": "2025-06-15T10:10:50Z",
        "media_urls": [
            "https://opengraph.githubassets.com/cb9a48cb63d687da78b3a206a2d1114736e7496be9288d16423b8ac6381f6f4d/dryeab/mcp-telegram"
        ],
        "homepage": "https://x.com/dryeab/status/1912187620131487999",
        "readme_summary": "The mcp-telegram repository enables Large Language Models (LLMs) to interact with Telegram through the Model Context Protocol (MCP). It allows AI agents to perform actions such as sending messages, searching chats, managing drafts, and handling media using the Telethon library and MTProto.",
        "key_features": [
            "Connects LLMs to Telegram",
            "Enables sending, editing, and deleting messages",
            "Allows searching chats and managing drafts",
            "Supports media downloading",
            "Uses Telethon and MTProto for Telegram interaction"
        ],
        "primary_use_case": "Allowing AI agents to control and interact with Telegram accounts for various automated tasks and integrations.",
        "open_issues": 4,
        "cover_image_prompt": "A diligent librarian meticulously organizing countless telegrams, each representing a message or interaction. The librarian uses a special interface that translates natural language requests into precise Telegram actions, sorting and filing the telegrams accordingly. Small screens display snippets of code and MCP commands, subtly connecting the scene to software. The setting is a vast, futuristic library filled with glowing data streams. The composition is clean and focused, with a blue and green color scheme. The image should be in a 3D isometric illustration style with rich details and vibrant colors."
    }
]