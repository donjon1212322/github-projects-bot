[
    {
        "id": 969487233,
        "name": "register",
        "description": "Community-maintained registry for free subdomains â€” 100% free",
        "url": "https://github.com/domainsproject/register",
        "language": "JavaScript",
        "stars": 29,
        "forks": 15,
        "created_at": "2025-04-20T09:03:01Z",
        "updated_at": "2025-05-05T09:58:03Z",
        "topics": [
            "dns",
            "domains",
            "free",
            "open-source",
            "subdomains"
        ],
        "quality_score": 0.95,
        "contributors_count": 0,
        "last_commit_date": "2025-05-05T09:57:59Z",
        "media_urls": [
            "https://opengraph.githubassets.com/0f791b4350b28083179ea013e73fc76af18fe3a58d219e22287cc49f4a109dff/domainsproject/register"
        ],
        "homepage": "https://getyourfree.space/",
        "readme_summary": "The 'register' repository offers a community-maintained registry for free subdomains. It allows users to register subdomains under the `owns.it.com` domain for showcasing their projects. The service includes features like DNSSEC protection, SSL/TLS, and provides setup guides for popular hosting providers, making it easy to deploy websites with a free subdomain.",
        "key_features": [
            "Free subdomain registration",
            "DNSSEC protection",
            "Email support",
            "Full SSL/TLS",
            "HTTPS enforcement",
            "HSTS security",
            "TLS 1.2+ required",
            "WAF protection",
            "Browser integrity checks",
            "Setup guides for various hosting providers"
        ],
        "primary_use_case": "Providing free subdomains for personal projects and websites.",
        "open_issues": 0,
        "cover_image_prompt": "A community garden where each plot represents a subdomain, and gardeners (users) are planting their websites. A central watering system (the registry) ensures all plots are thriving. The garden is surrounded by a digital fence with glowing code patterns, subtly connecting it to the internet. A sign at the entrance reads 'Free Subdomains for Everyone!' in a friendly font. The scene is set in a sunny, vibrant landscape with a clear blue sky. The image should be in a flat design style with clear iconography and bright colors."
    },
    {
        "id": 971293318,
        "name": "Step1X-Edit",
        "description": "A SOTA open-source image editing model, which aims to provide comparable performance against the closed-source models like GPT-4o and Gemini 2 Flash.",
        "url": "https://github.com/stepfun-ai/Step1X-Edit",
        "language": "Python",
        "stars": 1055,
        "forks": 49,
        "created_at": "2025-04-23T09:53:08Z",
        "updated_at": "2025-05-05T07:53:29Z",
        "topics": [],
        "quality_score": 0.8,
        "contributors_count": 0,
        "last_commit_date": "2025-05-01T13:55:36Z",
        "media_urls": [
            "https://opengraph.githubassets.com/f82c8480f4184770c496c58cfd74d344d6b07216e0a7d431a2db6799c113db31/stepfun-ai/Step1X-Edit"
        ],
        "homepage": "https://step1x-edit.github.io",
        "readme_summary": "Step1X-Edit is an open-source image editing model designed to rival the performance of proprietary models like GPT-4o and Gemini 2 Flash. It offers features such as ComfyUI plugin support, FP8 quantization, and an online demo for immediate use. The project also provides evaluation code and benchmark data for assessing its capabilities.",
        "key_features": [
            "State-of-the-art image editing",
            "Comparable performance to closed-source models like GPT-4o and Gemini 2 Flash",
            "ComfyUI Plugin support",
            "FP8 Quantized weight support",
            "Online demo available",
            "Evaluation code and benchmark data (GEdit-Bench) released"
        ],
        "primary_use_case": "Image editing with a focus on achieving high performance comparable to leading closed-source models.",
        "open_issues": 21,
        "cover_image_prompt": "Imagine a skilled artisan meticulously refining a rough gemstone with precision tools, transforming it into a dazzling, multifaceted jewel. The artisan represents the Step1X-Edit model, and the gemstone symbolizes a raw, unedited image. As the artisan works, subtle UI elements float around the scene, displaying image editing parameters and real-time adjustments. Digital particles shimmer around the jewel, highlighting the transformative process. The repository name, 'Step1X-Edit,' is subtly etched onto one of the artisan's tools. The scene is bathed in soft, focused lighting, emphasizing the artisan's craftsmanship. The image should be in a 3D isometric illustration style with rich details and vibrant colors."
    },
    {
        "id": 17371412,
        "name": "h2o-3",
        "description": "H2O is an Open Source, Distributed, Fast & Scalable Machine Learning Platform: Deep Learning, Gradient Boosting (GBM) & XGBoost, Random Forest, Generalized Linear Modeling (GLM with Elastic Net), K-Means, PCA, Generalized Additive Models (GAM), RuleFit, Support Vector Machine (SVM), Stacked Ensembles, Automatic Machine Learning (AutoML), etc.",
        "url": "https://github.com/h2oai/h2o-3",
        "language": "Jupyter Notebook",
        "stars": 7140,
        "forks": 2014,
        "created_at": "2014-03-03T16:08:07Z",
        "updated_at": "2025-05-05T09:33:44Z",
        "topics": [
            "automl",
            "big-data",
            "data-science",
            "deep-learning",
            "distributed",
            "ensemble-learning",
            "gbm",
            "gpu",
            "h2o",
            "h2o-automl",
            "hadoop",
            "java",
            "machine-learning",
            "naive-bayes",
            "opensource",
            "pca",
            "python",
            "r",
            "random-forest",
            "spark"
        ],
        "quality_score": 1.1000000000000003,
        "contributors_count": 0,
        "last_commit_date": "2025-04-11T00:08:24Z",
        "media_urls": [
            "https://opengraph.githubassets.com/cfee60b824afb3b71eccc113b60ac9b597bc5837d4e1e83cf273a1cfd33cb541/h2oai/h2o-3"
        ],
        "homepage": "http://h2o.ai",
        "readme_summary": "H2O is an open-source, distributed machine learning platform that provides a wide range of algorithms and tools for building and deploying scalable models. It supports various programming languages and integrates seamlessly with big data technologies like Hadoop and Spark. H2O allows users to build, train, and deploy machine learning models for various applications.",
        "key_features": [
            "Distributed machine learning platform",
            "Algorithms: Deep Learning, Gradient Boosting (GBM), XGBoost, Random Forest, GLM, K-Means, PCA, GAM, RuleFit, SVM, Stacked Ensembles, AutoML",
            "Support for R, Python, Scala, Java, JSON",
            "Integration with Hadoop and Spark",
            "Model export to POJO/MOJO for production deployment"
        ],
        "primary_use_case": "Building and deploying scalable machine learning models for big data applications.",
        "open_issues": 2816,
        "cover_image_prompt": "A skilled architect overseeing a vast construction site where complex algorithms are being assembled into a magnificent, scalable machine learning platform. The architect holds blueprints representing various algorithms like Deep Learning, GBM, and AutoML, directing robotic arms that precisely place each component. Data streams flow into the platform, powering its intelligent operations. Holographic displays show real-time performance metrics and visualizations. The scene is set in a futuristic, brightly lit control room with a clean, organized layout. The image should be in a 3D isometric illustration style with vibrant colors and intricate details."
    },
    {
        "id": 686364232,
        "name": "openllmetry",
        "description": "Open-source observability for your LLM application, based on OpenTelemetry",
        "url": "https://github.com/traceloop/openllmetry",
        "language": "Python",
        "stars": 5764,
        "forks": 727,
        "created_at": "2023-09-02T14:42:59Z",
        "updated_at": "2025-05-05T09:56:27Z",
        "topics": [
            "artifical-intelligence",
            "datascience",
            "generative-ai",
            "good-first-issue",
            "good-first-issues",
            "help-wanted",
            "llm",
            "llmops",
            "metrics",
            "ml",
            "model-monitoring",
            "monitoring",
            "observability",
            "open-source",
            "open-telemetry",
            "opentelemetry",
            "opentelemetry-python",
            "python"
        ],
        "quality_score": 0.85,
        "contributors_count": 0,
        "last_commit_date": "2025-04-30T12:41:29Z",
        "media_urls": [
            "https://opengraph.githubassets.com/c9b53d2e162f0a1b85bda360c51222ba8ee5842d5540cfe0326c1182bf4a29eb/traceloop/openllmetry"
        ],
        "homepage": "https://www.traceloop.com/openllmetry",
        "readme_summary": "OpenLLMetry provides open-source observability for LLM applications by extending OpenTelemetry. It offers instrumentations for LLM providers and Vector DBs and a Traceloop SDK for simplified integration. OpenLLMetry enables connection to existing observability solutions, providing comprehensive monitoring and insights into LLM application performance.",
        "key_features": [
            "OpenTelemetry extensions for LLM applications",
            "Instrumentation for LLM providers and Vector DBs",
            "Traceloop SDK for easy OpenLLMetry integration",
            "Integration with existing observability solutions (Datadog, Honeycomb, etc.)"
        ],
        "primary_use_case": "Observability for LLM applications",
        "open_issues": 81,
        "cover_image_prompt": "Imagine a skilled cartographer meticulously charting the vast and complex landscape of a sprawling city, representing an LLM application. The cartographer uses specialized tools that glow with digital light, revealing hidden patterns and connections within the city's intricate network of buildings (representing LLM components). OpenTelemetry symbols subtly appear as landmarks on the map, guiding the cartographer. The scene is bathed in soft, ethereal light, creating a sense of discovery and understanding. This conceptual illustration, in a 3D isometric style, should evoke clarity and insight into LLM observability."
    },
    {
        "id": 213390927,
        "name": "alibi-detect",
        "description": "Algorithms for outlier, adversarial and drift detection",
        "url": "https://github.com/SeldonIO/alibi-detect",
        "language": "Jupyter Notebook",
        "stars": 2361,
        "forks": 229,
        "created_at": "2019-10-07T13:29:13Z",
        "updated_at": "2025-05-05T04:48:44Z",
        "topics": [
            "adversarial",
            "anomaly",
            "concept-drift",
            "data-drift",
            "detection",
            "drift-detection",
            "images",
            "outlier",
            "semi-supervised-learning",
            "tabular-data",
            "text",
            "time-series",
            "unsupervised-learning"
        ],
        "quality_score": 0.7,
        "contributors_count": 0,
        "last_commit_date": "2025-03-05T13:25:02Z",
        "media_urls": [
            "https://opengraph.githubassets.com/447af59b9163cf0ef0f143956bb28ab44ffa67755e6ce2d2dfd93909040f57be/SeldonIO/alibi-detect"
        ],
        "homepage": "https://docs.seldon.io/projects/alibi-detect/en/stable/",
        "readme_summary": "Alibi Detect is a Python library for outlier, adversarial, and drift detection. It supports various data types, including tabular data, text, images, and time series. The library provides both online and offline detectors and supports TensorFlow and PyTorch backends for drift detection.",
        "key_features": [
            "Outlier detection",
            "Adversarial detection",
            "Drift detection",
            "Support for tabular data, text, images, and time series",
            "TensorFlow and PyTorch backends for drift detection"
        ],
        "primary_use_case": "Detecting outliers, adversarial attacks, and drift in machine learning models.",
        "open_issues": 124,
        "cover_image_prompt": "A seasoned detective meticulously examining data streams flowing through a complex network of pipes, searching for anomalies and disruptions. The detective uses a magnifying glass to inspect the data, revealing outliers and adversarial attacks as glowing red particles. A small screen displays real-time drift detection metrics. The scene is set in a futuristic data center with cool, blue lighting. The composition is focused and clean, with a clear visual hierarchy. The image should be in a 3D isometric illustration style with crisp details and a touch of science fiction."
    },
    {
        "id": 648474263,
        "name": "DB-GPT-Hub",
        "description": "A repository that contains models, datasets, and fine-tuning techniques for DB-GPT, with the purpose of enhancing model performance  in Text-to-SQL",
        "url": "https://github.com/eosphoros-ai/DB-GPT-Hub",
        "language": "Python",
        "stars": 1755,
        "forks": 222,
        "created_at": "2023-06-02T03:58:07Z",
        "updated_at": "2025-05-05T04:48:25Z",
        "topics": [
            "database",
            "datasets",
            "fine-tuning",
            "gpt",
            "hacktoberfest",
            "llm",
            "nl2sql",
            "sql",
            "text-to-sql",
            "text2sql"
        ],
        "quality_score": 0.75,
        "contributors_count": 0,
        "last_commit_date": "2025-02-19T01:51:32Z",
        "media_urls": [
            "https://opengraph.githubassets.com/963415d5c91636d1e9c94764c55b0032868af23a983cfaeaed64a90ca2bbc05d/eosphoros-ai/DB-GPT-Hub"
        ],
        "homepage": "",
        "readme_summary": "DB-GPT-Hub is a repository focused on improving Text-to-SQL performance by providing models, datasets, and fine-tuning techniques. It supports fine-tuning for Text2SQL, Text2NLU, and Text2GQL, and includes evaluation benchmarks using the execution accuracy metric. The repository offers resources for training and evaluating models like Llama2 and CodeLlama using methods like LoRA and QLoRA.",
        "key_features": [
            "Text2SQL fine-tuning",
            "Text2NLU fine-tuning for improved semantic understanding",
            "Text2GQL fine-tuning for generating graph queries",
            "Evaluation benchmarks for Text2SQL performance using execution accuracy (EX) metric",
            "Support for multiple models (Llama2, CodeLlama) and fine-tuning methods (LoRA, QLoRA)"
        ],
        "primary_use_case": "Enhancing model performance in Text-to-SQL parsing using fine-tuning techniques, datasets, and models.",
        "open_issues": 68,
        "cover_image_prompt": "A skilled artisan meticulously crafting SQL queries from raw text using a sophisticated loom. The loom weaves together natural language threads into precise SQL code, displayed on a holographic screen beside the artisan. The scene is set in a bright, airy workshop filled with spools of colorful linguistic data. Subtle tech elements, like floating code snippets and database icons, enhance the connection to software. The composition is clean and focused, with a vibrant color scheme. The image should be in a 3D isometric illustration style with rich details and vibrant colors."
    },
    {
        "id": 954177450,
        "name": "TripoSG",
        "description": "TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models",
        "url": "https://github.com/VAST-AI-Research/TripoSG",
        "language": "Python",
        "stars": 1103,
        "forks": 97,
        "created_at": "2025-03-24T17:18:15Z",
        "updated_at": "2025-05-05T09:55:13Z",
        "topics": [
            "3d-genai",
            "3d-generation",
            "3d-reconstruction",
            "image-to-3d"
        ],
        "quality_score": 0.75,
        "contributors_count": 0,
        "last_commit_date": "2025-04-18T06:58:51Z",
        "media_urls": [
            "https://opengraph.githubassets.com/ba86129fc95a3fb226b5622396153f5c1e4edfbbd57313f4b0b38f8c63e8a2c4/VAST-AI-Research/TripoSG"
        ],
        "homepage": "",
        "readme_summary": "TripoSG is a high-fidelity image-to-3D generation model that leverages rectified flow transformers and a high-quality dataset. It produces meshes with sharp geometric features and strong generalization capabilities, handling diverse input styles while maintaining semantic consistency. The model enables the creation of coherent 3D shapes from images, even with complex topologies.",
        "key_features": [
            "High-Fidelity Generation",
            "Semantic Consistency",
            "Strong Generalization",
            "Robust Performance"
        ],
        "primary_use_case": "Image-to-3D shape generation",
        "open_issues": 23,
        "cover_image_prompt": "Imagine a skilled sculptor meticulously crafting a complex 3D model from a simple 2D image projected onto a screen. The sculptor's hands glow with digital energy as they mold the virtual clay, adding intricate details and refining the shape. The resulting 3D model stands proudly beside the screen, showcasing its high fidelity and semantic accuracy. Subtle UI elements and code snippets float in the background, connecting the artistic process to the underlying technology. The scene is set in a bright, modern studio with soft, diffused lighting. The image should be in a 3D isometric illustration style with vibrant colors and sharp details."
    },
    {
        "id": 907283665,
        "name": "pasa",
        "description": "PaSa -- an advanced paper search agent powered by large language models. It can autonomously make a series of decisions, including invoking search tools, reading papers, and selecting relevant references, to ultimately obtain comprehensive and accurate results for complex scholarly queries.",
        "url": "https://github.com/bytedance/pasa",
        "language": "Python",
        "stars": 1142,
        "forks": 82,
        "created_at": "2024-12-23T08:38:18Z",
        "updated_at": "2025-05-05T08:06:55Z",
        "topics": [
            "research"
        ],
        "quality_score": 0.65,
        "contributors_count": 0,
        "last_commit_date": "2025-02-07T03:18:27Z",
        "media_urls": [
            "https://opengraph.githubassets.com/91e39e03e145e82c413e6ca7354cbed03ae14353b41afc7743f1d3d5a67b4839/bytedance/pasa"
        ],
        "homepage": "",
        "readme_summary": "PaSa is an advanced paper search agent that utilizes large language models to autonomously search for academic papers. It employs reinforcement learning and a dual-agent system (Crawler and Selector) to efficiently process queries, read papers, and select relevant references. PaSa is designed to provide comprehensive and accurate results, outperforming existing baselines in real-world academic search scenarios.",
        "key_features": [
            "Autonomous paper search agent",
            "Powered by large language models",
            "Reinforcement learning optimization",
            "Synthetic and real-world datasets",
            "Crawler and Selector LLM agents"
        ],
        "primary_use_case": "Comprehensive and accurate academic paper search for complex scholarly queries.",
        "open_issues": 14,
        "cover_image_prompt": "Imagine a diligent librarian meticulously researching a complex query within a vast, glowing digital library. The librarian, equipped with advanced lenses displaying snippets of code and data visualizations, navigates towering shelves filled with papers represented as glowing tablets. As the librarian identifies relevant papers, they are carefully placed onto a central holographic display, forming a comprehensive knowledge graph. Subtle UI elements float in the background, showcasing search parameters and result metrics. The scene is bathed in soft, ethereal light, creating an atmosphere of focused discovery. The image should be in a detailed digital painting style with clean lines and vibrant colors, emphasizing clarity and understanding."
    },
    {
        "id": 935736274,
        "name": "apple-mcp",
        "description": "Collection of apple-native tools for the model context protocol.",
        "url": "https://github.com/Dhravya/apple-mcp",
        "language": "TypeScript",
        "stars": 1492,
        "forks": 105,
        "created_at": "2025-02-19T23:50:49Z",
        "updated_at": "2025-05-05T09:40:51Z",
        "topics": [
            "applescripts",
            "modelcontextprotocol"
        ],
        "quality_score": 0.6,
        "contributors_count": 0,
        "last_commit_date": "2025-04-02T22:34:14Z",
        "media_urls": [
            "https://opengraph.githubassets.com/76d0c39762bcb6627739d7abf1788ce072e27ac09b6026b5fc5b348b8773ef29/Dhravya/apple-mcp"
        ],
        "homepage": "https://x.com/DhravyaShah/status/1892363590671233255",
        "readme_summary": "The apple-mcp repository provides a collection of Apple-native tools designed to interact with the Model Context Protocol (MCP). It enables users to automate tasks across various Apple applications like Messages, Notes, Calendar, and Maps. This allows for the creation of workflows that can be triggered and managed programmatically.",
        "key_features": [
            "Send messages using the Apple Messages app",
            "List, search, and read notes in Apple Notes app",
            "Search contacts",
            "Send and schedule emails with attachments",
            "List and search reminders",
            "Search and create calendar events",
            "Web search using DuckDuckGo",
            "Search locations and get directions in Maps"
        ],
        "primary_use_case": "Automating tasks and workflows across various Apple applications using the Model Context Protocol.",
        "open_issues": 11,
        "cover_image_prompt": "Imagine a skilled conductor leading an orchestra of Apple devices (iPhones, iPads, Macs) each playing a different instrument (representing Messages, Notes, Calendar, etc.). The conductor's baton is a stylized Apple Pencil, and musical notes are replaced with data packets flowing harmoniously. A subtle UI overlay on each device shows the 'apple-mcp' logo and relevant app interfaces. The scene is set in a modern, minimalist studio with soft, diffused lighting. The image should be in a 3D isometric illustration style with vibrant colors and crisp details."
    }
]