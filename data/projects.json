[
    {
        "id": 1079947190,
        "name": "edit-mind",
        "description": "Desktop app that indexes videos with AI (object detection, face recognition, emotion analysis), enables semantic search through natural language queries, and generates rough cuts ",
        "url": "https://github.com/IliasHad/edit-mind",
        "language": "TypeScript",
        "stars": 681,
        "forks": 34,
        "created_at": "2025-10-20T16:21:57Z",
        "updated_at": "2025-11-10T09:53:27Z",
        "topics": [
            "ai",
            "computer-vision",
            "electron",
            "face-recognition",
            "ml",
            "video-editing",
            "video-indexing",
            "video-processing"
        ],
        "quality_score": 0.9000000000000001,
        "contributors_count": 0,
        "last_commit_date": "2025-10-27T00:01:55Z",
        "media_urls": [
            "https://opengraph.githubassets.com/42cf5aa05ae3b8b431a1d1837e9e60aedc01151d72532d1efed6d04129b574fa/IliasHad/edit-mind"
        ],
        "homepage": "https://www.youtube.com/watch?v=Ky9v85Mk6aY",
        "readme_summary": "Edit Mind is a cross-platform desktop application that uses AI to index and analyze video libraries. It performs tasks such as transcription, object detection, face recognition, and semantic search, enabling users to quickly find specific shots and generate rough cuts based on natural language queries.",
        "key_features": [
            "Privacy-First (Local AI Processing)",
            "Deep Indexing (Transcription, Faces, Objects, Text, Colors)",
            "Semantic Search (Natural Language Video Search)",
            "AI-Generated Rough Cuts",
            "Cross-Platform (macOS, Windows, Linux)",
            "Plugin-Based Architecture (Python Plugins)"
        ],
        "primary_use_case": "Video indexing and semantic search for video editing workflows.",
        "open_issues": 1,
        "cover_image_prompt": "A librarian in a vast, futuristic video archive, using a special AI lens to instantly catalog and cross-reference video reels. The lens highlights faces, objects, and spoken words within the videos, creating a dynamic web of interconnected data. Small UI elements float around the librarian, displaying search queries and video timelines. The repository name, 'Edit Mind,' is subtly displayed on a nearby screen. The scene is set in a brightly lit, organized archive with a blue and green color scheme. The image should be in a 3D isometric illustration style with rich details and vibrant colors."
    },
    {
        "id": 993428214,
        "name": "razer-keyboard-highlighter",
        "description": "Support for highlighting keys when keys are held according to a configuration file with pywal, i3wm, sway and hyprland integrations",
        "url": "https://github.com/DuckTapeMan35/razer-keyboard-highlighter",
        "language": "Python",
        "stars": 38,
        "forks": 0,
        "created_at": "2025-05-30T19:18:24Z",
        "updated_at": "2025-11-09T19:17:49Z",
        "topics": [],
        "quality_score": 0.44999999999999996,
        "contributors_count": 0,
        "last_commit_date": "2025-09-13T18:53:20Z",
        "media_urls": [
            "https://opengraph.githubassets.com/eb38ab070f0567d00421c60d0538ebabae91c558475e5b3c607ca5f1baa9b364/DuckTapeMan35/razer-keyboard-highlighter"
        ],
        "homepage": "",
        "readme_summary": "The repository provides a way to highlight keys on a Razer keyboard based on a configuration file. It supports integrations with pywal for color theming and i3wm, sway, and hyprland for window manager awareness, allowing key highlighting to be context-aware. It utilizes a keyboard listener and a controller to achieve this functionality.",
        "key_features": [
            "Key highlighting based on configuration file",
            "Support for key combinations of any order/size",
            "pywal integration for color theming",
            "i3wm, sway, and hyprland integration for window manager awareness",
            "OpenRGB version available as a potentially safer alternative"
        ],
        "primary_use_case": "Highlighting specific keys on a Razer keyboard when they are pressed, providing visual feedback for specific keybindings or functions, especially within window manager environments.",
        "open_issues": 0,
        "cover_image_prompt": "A spotlight illuminating a mechanical keyboard on a stage, highlighting specific keys in vibrant colors. A conductor stands before the keyboard, orchestrating the light show with graceful movements. Small UI elements float around the keyboard, displaying configuration options and keybindings. The stage is set in a modern, minimalist studio with soft, diffused lighting. Digital particles emanate from the highlighted keys, creating a dynamic visual effect. The repository name is subtly displayed on a banner behind the stage. The image should be in 3D isometric illustration style with rich details and vibrant colors."
    },
    {
        "id": 960201379,
        "name": "describe-anything",
        "description": "[ICCV 2025] Implementation for Describe Anything: Detailed Localized Image and Video Captioning",
        "url": "https://github.com/NVlabs/describe-anything",
        "language": "Python",
        "stars": 1398,
        "forks": 78,
        "created_at": "2025-04-04T03:03:06Z",
        "updated_at": "2025-11-10T07:57:30Z",
        "topics": [
            "describe-anything",
            "detailed-localized-captioning",
            "large-multimodal-models",
            "vision-language-model"
        ],
        "quality_score": 0.45,
        "contributors_count": 0,
        "last_commit_date": "2025-06-26T03:57:51Z",
        "media_urls": [
            "https://opengraph.githubassets.com/ed20cf03811333ea2cb386cd45ecf449230b7ef9f7b76ee2d6eb5e7d921112b1/NVlabs/describe-anything"
        ],
        "homepage": "https://describe-anything.github.io/",
        "readme_summary": "The 'Describe Anything' repository provides an implementation for detailed localized image and video captioning. It allows users to input a region of interest (defined by points, boxes, scribbles, or masks) in an image or video and generates detailed descriptions for that region, and includes a new benchmark, DLC-Bench, for evaluating models on the DLC task.",
        "key_features": [
            "Detailed localized image captioning",
            "Detailed localized video captioning",
            "Support for various region input methods (points, boxes, scribbles, masks)",
            "Interactive Gradio demos for image and video captioning",
            "Integration with SAM (Segment Anything Model) for automated mask generation",
            "DLC-Bench benchmark for evaluation"
        ],
        "primary_use_case": "Generating detailed descriptions for specific regions of interest within images and videos.",
        "open_issues": 18,
        "cover_image_prompt": "A skilled cartographer meticulously examining a vast, unlabeled map through a high-powered magnifying glass. As the cartographer focuses on specific regions, detailed descriptions magically appear on the map, revealing hidden landmarks and intricate details. Small UI elements displaying image and video inputs are subtly integrated into the map's border. The scene is set in a sunlit library filled with ancient scrolls and digital screens. The image should be in a 3D isometric illustration style with warm colors and rich textures, showcasing the power of localized description."
    },
    {
        "id": 41215835,
        "name": "HandBrake",
        "description": "HandBrake's development repository ",
        "url": "https://github.com/HandBrake/HandBrake",
        "language": "C",
        "stars": 21239,
        "forks": 1531,
        "created_at": "2015-08-22T16:32:28Z",
        "updated_at": "2025-11-10T10:08:52Z",
        "topics": [
            "gplv2",
            "multi-platform",
            "video-transcoding"
        ],
        "quality_score": 0.85,
        "contributors_count": 0,
        "last_commit_date": "2025-11-03T18:16:44Z",
        "media_urls": [
            "https://opengraph.githubassets.com/fb5e76074581c392f089323028fc2ea87d96afa2c15492dfda2563a3d17b3309/HandBrake/HandBrake"
        ],
        "homepage": "https://handbrake.fr",
        "readme_summary": "HandBrake is an open-source video transcoder that converts videos into formats compatible with various devices, including mobile phones, tablets, TVs, and web browsers. It supports common video file formats and leverages tools like FFmpeg, x264, and x265 to create MP4, MKV, or WebM video files.",
        "key_features": [
            "Video transcoding",
            "Cross-platform support (Linux, Mac, Windows)",
            "Support for common video formats",
            "Leverages FFmpeg, x264, x265, SVT-AV1",
            "Output to MP4, MKV, WebM"
        ],
        "primary_use_case": "Converting video files into formats suitable for different devices and platforms.",
        "open_issues": 257,
        "cover_image_prompt": "A skilled artisan meticulously crafting video files on a magical loom. The loom weaves together raw video threads from various sources like DVDs, phones, and cameras, transforming them into polished, optimized video spools ready for different devices. Small UI elements on the loom display transcoding settings and progress. Digital particles flow around the loom, representing the underlying software processes. The scene is set in a bright, organized workshop with natural lighting. The composition is focused and clear, highlighting the transformation process. The image should be in 3D isometric illustration style with vibrant colors and rich details."
    },
    {
        "id": 1030897854,
        "name": "servy",
        "description": "Turn Any App into a Native Windows Service â€” Open-Source Alternative to NSSM, WinSW & FireDaemon Pro",
        "url": "https://github.com/aelassas/servy",
        "language": "C#",
        "stars": 621,
        "forks": 35,
        "created_at": "2025-08-02T15:09:07Z",
        "updated_at": "2025-11-10T09:15:50Z",
        "topics": [
            "service-manager",
            "service-wrapper",
            "servy"
        ],
        "quality_score": 0.8499999999999999,
        "contributors_count": 0,
        "last_commit_date": "2025-11-10T09:15:47Z",
        "media_urls": [
            "https://opengraph.githubassets.com/dcfb352ec7c8bc5db26a10bf74d68969b3352eecfc008f5c87c44fcc250f5208/aelassas/servy"
        ],
        "homepage": "https://servy-win.github.io",
        "readme_summary": "Servy is an open-source C# application that transforms any application into a native Windows service. It serves as an alternative to tools like NSSM, WinSW, and FireDaemon Pro, providing a way to manage applications as background services on Windows operating systems.",
        "key_features": [
            "Turns any application into a Windows service",
            "Open-source alternative to NSSM, WinSW & FireDaemon Pro"
        ],
        "primary_use_case": "Running applications as background services on Windows.",
        "open_issues": 2,
        "cover_image_prompt": "A skilled clockmaker meticulously crafting a complex clockwork mechanism where each gear represents a different application. The clock is housed within a transparent Windows icon, showcasing the intricate workings inside. The clockmaker carefully winds the mainspring, symbolizing the transformation of these applications into smoothly running Windows services. Subtle UI elements float around the scene, displaying service status and configuration options. The scene is set in a brightly lit workshop with a clean, technical illustration style. The image should be in 3D isometric illustration style with clear details and a focus on functionality."
    },
    {
        "id": 1083331153,
        "name": "vitest-react-profiler",
        "description": "React component render tracking and performance testing utilities for Vitest",
        "url": "https://github.com/greydragon888/vitest-react-profiler",
        "language": "TypeScript",
        "stars": 7,
        "forks": 0,
        "created_at": "2025-10-25T19:54:19Z",
        "updated_at": "2025-11-10T08:16:14Z",
        "topics": [],
        "quality_score": 0.95,
        "contributors_count": 0,
        "last_commit_date": "2025-11-06T13:43:43Z",
        "media_urls": [
            "https://opengraph.githubassets.com/cfd37d14122de720ff950f147ba2e11e146a452f216700182b127c2187c87619/greydragon888/vitest-react-profiler"
        ],
        "homepage": "",
        "readme_summary": "The `vitest-react-profiler` repository provides utilities for tracking React component renders and performance testing within Vitest. It allows developers to precisely measure render counts, monitor performance, detect render phases, and perform statistical analysis on render times, enhancing the reliability and efficiency of React component testing.",
        "key_features": [
            "Precise Render Tracking",
            "Performance Monitoring",
            "Phase Detection",
            "Statistical Analysis",
            "Async Testing",
            "True Automatic Cleanup",
            "Full TypeScript Support",
            "Battle-Tested Quality"
        ],
        "primary_use_case": "React component render tracking and performance testing using Vitest.",
        "open_issues": 1,
        "cover_image_prompt": "A seasoned watchmaker meticulously inspecting the gears of a complex clock representing a React component. The watchmaker uses specialized tools to measure the speed and precision of each gear's movement, ensuring optimal performance. Small screens display real-time render metrics and performance graphs. The workshop is filled with intricate clock parts and diagrams, illuminated by a soft, focused light. Digital particles subtly highlight the flow of data between the gears. The image should be in a detailed 3D isometric illustration style with a warm color scheme."
    }
]